{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c92f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "from lxml import etree\n",
    "from pymarc import map_records, map_xml, XMLWriter, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca88db",
   "metadata": {},
   "source": [
    "### Input and output file control\n",
    "The directory `input/cuc-export` is actually a simlink to another dir. Note that on macOS, you can't use Finder\n",
    "aliases for such links, you have to create actual symlinks with `ln -s` for this to work.\n",
    "\n",
    "#### File preparation\n",
    "The `cuclookup` file on the list below needs to be a csv (e.g. generated in MarcEdit) containing a list of \n",
    "`020$a` and `035\\$a` exported from the CUC file. Column must be named that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfc0b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "chathamxml = '../stclair-duplicates/input/chatham-records-20210928-fixed.xml'\n",
    "windsorxml = '../stclair-duplicates/input/windsor-records-20210928-fixed.xml'\n",
    "\n",
    "cucfiles = ['input/cuc-export/CUC_bib_01_final.xml', \\\n",
    "            'input/cuc-export/CUC_bib_02_final.xml', \\\n",
    "            'input/cuc-export/CUC_bib_03_final.xml', \\\n",
    "            'input/cuc-export/CUC_bib_04_final.xml', \\\n",
    "            'input/cuc-export/CUC_bib_05_final.xml']\n",
    "\n",
    "cuclookup = 'input/CUC-020-035-lookup.csv'\n",
    "\n",
    "chathamoutxml = 'output/chatham-records-cuc035-20220319.xml'\n",
    "windsoroutxml = 'output/windsor-records-cuc035-20220319.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0025e9",
   "metadata": {},
   "source": [
    "### Build CUC lookup dictionary\n",
    "This will be used to look up any 020s found in the St. Clair files and get the corresponding 035s if found.\n",
    "If more than one 020 exists for a particular record, an additional dictionary entry is created. Records where 035 is `nan` are excluded.\n",
    "\n",
    "035s can be multiple values split by `;` too, they will be handled individually in the mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d3f0511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "395315    None\n",
       "395316    None\n",
       "395317    None\n",
       "395318    None\n",
       "395319    None\n",
       "Length: 395320, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuc_df = pandas.read_csv(cuclookup)\n",
    "cuc_dict = {}\n",
    "def construct_dict(line):\n",
    "    ohtwooh = str(line['020$a'])\n",
    "    ohthreefive = str(line['035$a'])\n",
    "    if ohthreefive != 'nan':\n",
    "        isbns = ohtwooh.split(';')\n",
    "        if len(isbns) > 0:\n",
    "            for isbn in isbns:\n",
    "                cuc_dict[isbn]=ohthreefive\n",
    "\n",
    "cuc_df.apply(construct_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60fd42",
   "metadata": {},
   "source": [
    "### ISBN Helper functions\n",
    "Adapted from [ISBN-13 converter (Python recipe)](https://code.activestate.com/recipes/498104-isbn-13-converter/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2416a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_digit_10(isbn):\n",
    "    assert len(isbn) == 9\n",
    "    sum = 0\n",
    "    for i in range(len(isbn)):\n",
    "        c = int(isbn[i])\n",
    "        w = i + 1\n",
    "        sum += w * c\n",
    "    r = sum % 11\n",
    "    if r == 10: return 'X'\n",
    "    else: return str(r)\n",
    "\n",
    "def check_digit_13(isbn):\n",
    "    assert len(isbn) == 12\n",
    "    sum = 0\n",
    "    for i in range(len(isbn)):\n",
    "        c = int(isbn[i])\n",
    "        if i % 2: w = 3\n",
    "        else: w = 1\n",
    "        sum += w * c\n",
    "    r = 10 - (sum % 10)\n",
    "    if r == 10: return '0'\n",
    "    else: return str(r)\n",
    "\n",
    "def convert_10_to_13(isbn):\n",
    "    assert len(isbn) == 10\n",
    "    prefix = '978' + isbn[:-1]\n",
    "    check = check_digit_13(prefix)\n",
    "    return prefix + check\n",
    "\n",
    "def convert_13_to_10(isbn):\n",
    "    assert len(isbn) == 13\n",
    "    prefix = isbn[3:-1]\n",
    "    check = check_digit_10(prefix)\n",
    "    return prefix + check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974f420",
   "metadata": {},
   "source": [
    "### Define mapping function\n",
    "This function will be run on each record in the St.Clair dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5985dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks if the returned 035 is prefixed with either (OCoLC), (Sirsi) or (Local)\n",
    "# and return the first one found in that order, or None if none is found.\n",
    "def fieldmatch(array):\n",
    "    patterns = ['\\(OCoLC\\).*','\\(Sirsi\\).*','\\(Local\\).*']\n",
    "    for pattern in patterns:\n",
    "        regex_object = re.compile(pattern)\n",
    "        for string in array:\n",
    "            result = regex_object.match(string)\n",
    "            if result != None:\n",
    "                return result.group()\n",
    "    return None\n",
    "\n",
    "\n",
    "# This is the mapping function that is run on each source record\n",
    "def stclaircuc_map(record):\n",
    "    global counter\n",
    "    if record:\n",
    "        bibid = int(record['001'].value())\n",
    "        ohtwooh = record['020']\n",
    "        if (ohtwooh != None):\n",
    "            # Extract only the first part of the 020 string (before first space separator)\n",
    "            isbnraw = record['020'].value().split( )[0]\n",
    "            # Convert it into other ISBN variants\n",
    "            isbn_nodash = isbnraw.replace('-','')\n",
    "            if len(isbn_nodash) == 10:\n",
    "                isbn_13 = convert_10_to_13(isbn_nodash)\n",
    "                isbn_10 = isbn_nodash\n",
    "            elif len(isbn_nodash) == 13:\n",
    "                isbn_13 = isbn_nodash\n",
    "                isbn_10 = convert_13_to_10(isbn_nodash)\n",
    "            else:\n",
    "                # If the 020 string is neither 10 nor 13 characters long, it's likely not an ISBN, \n",
    "                # keep this record as-is and go to the next.\n",
    "                writer.write(record)\n",
    "                return\n",
    "            isbn_13_dashed = \"-\".join([isbn_13[0:3], isbn_13[3], isbn_13[4:7], isbn_13[7:12], isbn_13[12]])\n",
    "            isbn_10_dashed = \"-\".join([isbn_10[0], isbn_10[1:4], isbn_10[4:9], isbn_10[9]])\n",
    "            \n",
    "            isbn_variants = [isbn_13, isbn_10, isbn_13_dashed, isbn_10_dashed]\n",
    "            #print(bibid, ': ', isbn_variants)\n",
    "            \n",
    "            # Try to find a CUC record with one of those ISBN variants\n",
    "            for isbn in isbn_variants:\n",
    "                find035 = cuc_dict.get(isbn)\n",
    "                if find035 != None:\n",
    "                    # Check if one of the 035 for that record are among the ones we're looking for\n",
    "                    ohthreefive = fieldmatch(find035.split(';'))\n",
    "                    if ohthreefive != None:         \n",
    "                        # Check first if that 035 doesn't exist in the record already\n",
    "                        control = False\n",
    "                        existing_fields = record.get_fields('035')\n",
    "                        for existing in existing_fields:\n",
    "                            subfields = existing.get_subfields('a')\n",
    "                            if (len(subfields) > 0) and (subfields[0] == ohthreefive):\n",
    "                                control = True\n",
    "                        \n",
    "                        if control == False:\n",
    "                            record.add_field(\n",
    "                                Field(\n",
    "                                    tag = '035',\n",
    "                                    indicators = ['',''],\n",
    "                                    subfields = [\n",
    "                                        'a', ohthreefive\n",
    "                                    ]\n",
    "                                )\n",
    "                            )\n",
    "                            #print(bibid,',',ohthreefive,',',isbn)\n",
    "                            counter = counter + 1\n",
    "                    break\n",
    "                    \n",
    "        writer.write(record)\n",
    "    else:\n",
    "        print('Could not read record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444aa1c",
   "metadata": {},
   "source": [
    "### Run the mapping function\n",
    "This is where the magic happen. The mapping function is run on the Chatham and Windsor files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14bf4237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched  1240  Chatham records!\n"
     ]
    }
   ],
   "source": [
    "writer = XMLWriter(open(chathamoutxml,'wb'))\n",
    "counter = 0\n",
    "map_xml(stclaircuc_map, chathamxml)\n",
    "writer.close()\n",
    "print(\"Enriched \", counter, \" Chatham records!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb623431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched  2978  Windsor records!\n"
     ]
    }
   ],
   "source": [
    "writer = XMLWriter(open(windsoroutxml,'wb'))\n",
    "counter = 0\n",
    "map_xml(stclaircuc_map, windsorxml)\n",
    "writer.close()\n",
    "print(\"Enriched \", counter, \" Windsor records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548b9c6",
   "metadata": {},
   "source": [
    "### Old, inefficient way\n",
    "This was a terrible way to solve the problem. Xpath lookups are very slow. Stored here for posterity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cucparser = etree.XMLParser(encoding='utf-8',resolve_entities=False)\n",
    "\n",
    "# This probably takes a good deal of memory...\n",
    "cuctrees = list(map(lambda infile: etree.parse(infile, cucparser), cucfiles))\n",
    "\n",
    "# For reference, this is the old function that used a live xpath lookup in the CUC.\n",
    "def stclaircuc_map_old(record):\n",
    "    if record:\n",
    "        bibid = int(record['001'].value())\n",
    "        ohtwooh = record['020']\n",
    "        if (ohtwooh != None):\n",
    "            # Extract only the first part of the 020 string (before first space separator)\n",
    "            isbnraw = record['020'].value().split( )[0]\n",
    "            # Convert it into other ISBN variants\n",
    "            isbn_nodash = isbnraw.replace('-','')\n",
    "            if len(isbn_nodash) == 10:\n",
    "                isbn_13 = convert_10_to_13(isbn_nodash)\n",
    "                isbn_10 = isbn_nodash\n",
    "            elif len(isbn_nodash) == 13:\n",
    "                isbn_13 = isbn_nodash\n",
    "                isbn_10 = convert_13_to_10(isbn_nodash)\n",
    "            else:\n",
    "                # If the 020 string is neither 10 nor 13 characters long, it's likely not an ISBN, \n",
    "                # keep this record as-is and go to the next.\n",
    "                writer.write(record)\n",
    "                return\n",
    "            isbn_13_dashed = \"-\".join([isbn_13[0:3], isbn_13[3], isbn_13[4:7], isbn_13[7:12], isbn_13[12]])\n",
    "            isbn_10_dashed = \"-\".join([isbn_10[0], isbn_10[1:4], isbn_10[4:9], isbn_10[9]])\n",
    "            \n",
    "            isbn_variants = [isbn_13, isbn_10, isbn_13_dashed, isbn_10_dashed]\n",
    "            #print(bibid, ': ', isbn_variants)\n",
    "            \n",
    "            # Try to find a CUC record with one of those ISBN variants\n",
    "            xquery = \"//marc:datafield[@tag='020'][marc:subfield='\" \\\n",
    "                     + \"' or marc:subfield='\".join(isbn_variants) \\\n",
    "                     +\"']/../marc:datafield[@tag='035']//text()\"\n",
    "            #print(bibid, ': ', xquery)\n",
    "            for cuctree in cuctrees:\n",
    "                find035 = cuctree.xpath(xquery,namespaces = {\"marc\": \"http://www.loc.gov/MARC21/slim\"})\n",
    "                if len(find035) > 0:\n",
    "                    print(bibid, ': ', isbn_variants)\n",
    "                    print(bibid, ': ', find035)\n",
    "                    break\n",
    "            \n",
    "            for ohthreefive in find035:\n",
    "                record.add_field(\n",
    "                    Field(\n",
    "                        tag = '035',\n",
    "                        indicators = ['',''],\n",
    "                        subfields = [\n",
    "                            'a', ohthreefive\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "        writer.write(record)\n",
    "    else:\n",
    "        print('Could not read record')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
